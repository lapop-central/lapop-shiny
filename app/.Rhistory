value_recoded = col_character()
),
locale = locale(encoding = "UTF-8")
) %>%
clean_names()
target_vars <- questions_cats$column_name #unique columns to filter the data by
response_labels <- values_labels %>%
left_join(questions_cats, by = "column_name") %>%
select(column_name, paste0("question_",lang), value, value_recoded, paste0("label_",lang)) %>%
rename(label = starts_with("label_"), question = starts_with("question_"))
# Create countries lookup to Add country name into dataframe
countries <- response_labels %>%
filter(column_name == "pais") %>%
rename(country = label, pais = value) %>%
select(pais, value_recoded)
# This function checks if pais column exists in the dataframe
check_pais <- function(df, filename){
# inputs :
# df - dataframe to be used
# filename - the name of the file being imported
# output : dataframe with correct country as a column
if(! "pais" %in% colnames(df)){
print("'pais' missing!")
}
return(df)
}
# This function checks if year column exists in the dataframe, and if it does then it makes sure that the year matches the year in filename.  If it doesn't then it adds the year from the name of file.
add_year <- function(df, filename){
# inputs :
# df - dataframe to be used
# filename - the name of the file being imported
# output : dataframe with correct year as a column
if(!("year" %in% names(df))){
year <- str_extract(filename, "\\d{4}")
df$year <- year
cat(paste0("\nSet year to ",year))
}
return(df)
}
ts.list <- list.files("data",pattern = "_ts_.*.dta",full.names = T)
cy.list <- list.files("data",pattern = "_cy_.*.dta",full.names = T)
country.abb <- unique(str_extract(list.files("data",pattern = ".dta"),"^.{3}"))
get_filenames <- function(abb){
filename <- grep(abb,ts.list,value = T)
if(length(filename)<1){
filename <- grep(abb, cy.list, value = T)
}
return(filename)
}
country.filenames <- sapply(country.abb, get_filenames)
country.filenames[["all"]] <- NULL
# Function to read in and clean up a dataframe, given a filename to a .dta
get_country_df <- function(filepath = country.filenames[[1]]){
cat(paste0("\nWorking on ",filepath,"... "))
country_df <- read_dta(filepath,encoding = "latin1") %>%
clean_names() %>%
zap_labels() %>%
check_pais(filename = filepath) %>%
add_year(filename = filepath) #%>%
return(country_df)
}
# Function to generate unique id's that contain year, country and observation info
add_uniqueID <- function(df) {
df <- df %>%
mutate(person_id = paste(year, pais, idnum,sep = "_")) %>%
group_by(person_id) %>%
mutate(id_count = row_number()) %>%
ungroup() %>%
mutate(person_id = paste(person_id, id_count, sep = "_"),
id_count = NULL)
#Adding more stuff to id because some files have non-unique ids
assert(df, is_uniq, person_id)
return(df)
}
# df <- add_uniqueID(get_country_df())
add_weight1500 <- function(country_df) {
#creates final output variable
if (!"weight1500"%in%names(country_df)){
country_df <- mutate(country_df, weight1500=wt/n()*1500)
}
return(country_df)
}
#
# country_list <- lapply(file_data$dta_files, get_country_dfs)
country.dfs <- sapply(country.filenames, get_country_df)
# Combining the list of dataframes into one data frame.
country.dfs.tidied <- sapply(country.dfs, function(df){
df %>%
add_uniqueID() %>%
add_weight1500() %>%
select(person_id, one_of(target_vars)) %>%
mutate_at(vars(contains('idnum')), as.character) %>%
mutate_at(vars(contains('pais')), as.numeric) %>%
mutate_at(vars(contains('year')), as.numeric) %>%
mutate_at(vars(contains('clusterdesc')), as.character)
})
all.df <- reduce(country.dfs.tidied, bind_rows)
# Adding full country names to data frame.
all.df <- left_join(all.df,
(
response_labels %>%
filter(column_name == "pais") %>%
mutate_at(vars(("value")), as.double) %>%
select(value, label)
),
by = c("pais" = "value")) %>%
mutate(country = label)
all.df %>% select("person_id","wt","weight1500", everything()) %>% head()
all.df %>% assert(is_uniq, person_id)
all.df <- all.df[!(all.df$country == "Colombia" & (all.df$year == 2005 | all.df$year == 2007 | all.df$year == 2009 | all.df$year == 2011)), ]
# delete haiti 2012 temporarily
# all.df <- all.df[!(all.df$country == "Haiti" & (all.df$year == 2012)), ]
write_csv(all.df, paste0("all.df.", lang,".csv"))
all.df <- read_csv(paste0("all.df.", lang,".csv"),col_types = cols(.default = col_double(),
person_id = col_character(),
label = col_character(),
country = col_character()))
memory.limit(size=25000)
question_list <- colnames(all.df)
remove <- c('pais','person_id','weight1500','country','X1')
question_list <- question_list[!question_list %in% remove]
final_data_long <- all.df %>%
# group_by(person_id,country) %>% # >> hack added to make person_id unique
# mutate(rowid = row_number()) %>%
# ungroup() %>%
# mutate(person_id = paste(person_id, rowid, sep="_")) %>%
# select(-rowid) %>%# << hack added to make person_id unique
gather(column_name, answer_measure, question_list) %>%
select(person_id,pais,country,column_name,answer_measure,weight1500)
# library(stringr)
# problematic <- filter(final_data_long, answer_measure%in%c(98,99,100)&column_name!="q2")
# table(problematic$column_name,problematic$answer_measure)
# table(problematic$column_name,str_match(problematic$person_id,".{3}(\\d{2})")[,2])
# table(problematic$column_name,problematic$country)
# table(problematic$answer_measure)
# problematic %>% filter(answer_measure==100)
total_long_common_recoded <- final_data_long %>%
mutate(answer_measure = as.character(answer_measure)) %>%
left_join(response_labels,
by = c("column_name" = "column_name", "answer_measure" = "value")) %>%
mutate(answer_dimension = label,
# mutate(answer_dimension = if_else(column_name=="year"|is.na(label), #make sure year is ok for dropdown menu
#                                   label,
#                                   paste0(answer_measure, ": ", label)), # use this to produce value and label (e.g. "7: Strongly Agree")
answer_measure = if_else(is.na(value_recoded),answer_measure,value_recoded)
)
# hack to get better labels on crosstab
# group_by(column_name) %>%
# mutate(sortid=as.integer(as.factor(answer_measure))) %>%
# mutate(sortid=max(sortid,na.rm = T)-sortid) %>%
# ungroup() %>%
# mutate(answer_dimension = if_else(is.na(label_es),
#                                   label_es,
#                                   str_c('"',str_dup(" ",sortid), label_es,'"')),
#        sortid = NULL)
# Separate our q2 rows, add agegroup, then bind all together
common_only_q2 <-
total_long_common_recoded %>% filter(column_name == "q2") %>%
mutate(answer_dimension = as.character(cut(
as.numeric(answer_measure),
breaks = c(0, 25, 35, 45, 55, 65, Inf),
labels = c("18-25", "26-35", "36-45", "46-55", "56-65", "66-")
)))
# stacking back into full data
total_long_common_recoded <- total_long_common_recoded %>%
filter(column_name !="q2") %>%  #Only non-q2 rows left
bind_rows(common_only_q2)
total_long_common_recoded %>%
filter(column_name == 'q2') %>%
select(answer_measure,answer_dimension)
total_long_common_recoded %>%
filter(column_name == 'year') %>%
distinct(answer_measure)
total_long_common_narrow <- total_long_common_recoded %>%
left_join(questions_cats, by = "column_name") %>%
rename(category_short = paste0("category_short_",lang), question_short = paste0("question_short_",lang)) %>%
unite(category_question, category_short, question_short, sep = ":", remove = FALSE) %>%
unite(category_colname, category_short, column_name, sep = ":", remove = FALSE) %>%
select(country, person_id, weight1500, column_name, category_question, category_colname, question_short, column_name, answer_measure, answer_dimension)
measures <- c(
"a4",
"aoj11",
"aoj12",
"b1",
"b12",
"b13",
"b18",
"b2",
"b20",
"b20a",
"b21",
"b21a",
"b3",
"b31",
"b32",
"b37",
"b4",
"b47a",
"b6",
"cct1b",
"clien1n",
"clien1na",
"cp13",
"cp2",
"cp20",
"cp6",
"cp7",
"cp8",
"d1",
"d2",
"d3",
"d4",
"d5",
"d6",
"drk1",
"dst1b",
"e5",
"ed",
"eff1",
"eff2",
"env1c",
"env2b",
"etid",
"exc11",
"exc13",
"exc14",
"exc15",
"exc16",
"exc18",
"exc2",
"exc20",
"exc6",
"exc7",
"exc7new",
"fs2",
"fs8",
"gi0",
"gi0n",
"idio2",
"infrax",
"ing4",
"it1",
"jc10",
"jc13",
"jc15a",
"jc16a",
"l1",
"l1b",
"leng1",
"lib1",
"lib2c",
"m1",
"mil10a",
"mil10e",
"np1",
"ocup1a",
"ocup4a",
"pn4",
"pol1",
"prot3",
"q1",
"q10a",
"q10e",
"q10new",
"q11n",
"q12",
"q12bn",
"q12c",
"q14",
"q2",
"q3cn",
"q5a",
"q5b",
"r1",
"r12",
"r14",
"r15",
"r16",
"r18",
"r3",
"r4",
"r4a",
"r5",
"r6",
"r7",
"r8",
"redist1",
"redist2",
"redist2a",
"redist3",
"ros4",
"sd2new2",
"sd3new2",
"sd6new2",
"smedia1",
"smedia4",
"smedia7",
"soct2",
"vb10",
"vb2",
"vb20",
"vb50",
"vb51",
"vb52",
"vic1ext",
"vic1exta",
"w14a",
"wf1"
)
dimensions <- c(
"a4",
"aoj11",
"aoj12",
"b1",
"b12",
"b13",
"b18",
"b2",
"b20",
"b20a",
"b21",
"b21a",
"b3",
"b31",
"b32",
"b37",
"b4",
"b47a",
"b6",
"cct1b",
"clien1n",
"clien1na",
"cp13",
"cp2",
"cp20",
"cp6",
"cp7",
"cp8",
"d1",
"d2",
"d3",
"d4",
"d5",
"d6",
"drk1",
"dst1b",
"e5",
"ed",
"eff1",
"eff2",
"env1c",
"env2b",
"etid",
"exc11",
"exc13",
"exc14",
"exc15",
"exc16",
"exc18",
"exc2",
"exc20",
"exc6",
"exc7",
"exc7new",
"fs2",
"fs8",
"gi0",
"gi0n",
"idio2",
"infrax",
"ing4",
"it1",
"jc10",
"jc13",
"jc15a",
"jc16a",
"l1",
"l1b",
"leng1",
"lib1",
"lib2c",
"m1",
"mil10a",
"mil10e",
"np1",
"ocup1a",
"ocup4a",
"pn4",
"pol1",
"prot3",
"q1",
"q10a",
"q10e",
"q10new",
"q11n",
"q12",
"q12bn",
"q12c",
"q14",
"q2",
"q3cn",
"q5a",
"q5b",
"r1",
"r12",
"r14",
"r15",
"r16",
"r18",
"r3",
"r4",
"r4a",
"r5",
"r6",
"r7",
"r8",
"redist1",
"redist2",
"redist2a",
"redist3",
"ros4",
"sd2new2",
"sd3new2",
"sd6new2",
"smedia1",
"smedia4",
"smedia7",
"soct2",
"ur",
"vb10",
"vb2",
"vb20",
"vb50",
"vb51",
"vb52",
"vic1ext",
"vic1exta",
"w14a",
"wf1",
"year"
)
measure.df <-
total_long_common_narrow %>% # Include only measures (cols with recode)
filter(
column_name %in% measures
) %>%
pivot_wider(
id_cols = c(person_id, country,weight1500),
names_from = column_name,
values_from = answer_measure
) %>% rename_at(measures, ~ paste0(.,"_m"))
dimension.df <-
total_long_common_narrow %>% # Include only dimensions (cols with label or no recode )
filter(
column_name %in% dimensions
) %>%
pivot_wider(
id_cols = c(person_id, country,weight1500),
names_from = column_name,
values_from = answer_dimension
) %>% rename_at(dimensions, ~ paste0(.,"_d"))
measure.label.df <-
total_long_common_narrow %>% # Include only measures (cols with recode)
filter(
column_name %in% measures
) %>%
pivot_wider(
id_cols = c(person_id, country,weight1500),
names_from = column_name,
values_from = answer_dimension
) %>% rename_at(measures, ~ paste0(.,"_l"))
dimension.order.df <-
total_long_common_narrow %>% # Include only dimensions (cols with label or no recode )
filter(
column_name %in% dimensions
) %>%
pivot_wider(
id_cols = c(person_id, country,weight1500),
names_from = column_name,
values_from = answer_measure
) %>% rename_at(dimensions, ~ paste0(.,"_o"))
final_wide <- measure.df %>%
left_join(dimension.df, by = c("person_id", "country",'weight1500')) %>%
left_join(measure.label.df, by = c("person_id", "country",'weight1500')) %>%
left_join(dimension.order.df, by = c("person_id", "country",'weight1500'))
#tableau 2021.4 was not adequately recognizing slashes, just using year_o
final_wide$year_d <- final_wide$year_o
#manually change weights from Haiti 2012, which are messed up in the data files
# final_wide$weight1500[final_wide$country == "Haití" & final_wide$year_o == 2012] <- final_wide$weight1500[final_wide$country == "Haití" & final_wide$year_o == 2012] / (1557.148/1500)
# final_wide$weight1500[final_wide$country == "Haiti" & final_wide$year_o == 2012] <- final_wide$weight1500[final_wide$country == "Haiti" & final_wide$year_o == 2012] / (1557.148/1500)
table(final_wide$year_d)
# write_csv(final_wide, "lapop_wide_en_v2.csv", na = "NULL ")
write_csv(final_wide, paste0("lapop_wide_", lang,"_v5.csv"), na = "NULL ")
library(lapop)
library(ggplot2)
lapop_fonts()
library(shiny)
runApp("~/shinyapp")
runApp("C:/Users/plutowl/Documents/GitHub/lapop-shiny/shinyapp")
runApp('Documents/GitHub/lapop-shiny')
runApp('Documents/GitHub/lapop-shiny')
mpgData <- mtcars
mpgData
mpgData$am <- factor(mpgData$am, labels = c("Automatic", "Manual"))
mpgData
runApp('Documents/GitHub/lapop-shiny')
runApp('Documents/GitHub/lapop-shiny')
runApp('Documents/GitHub/lapop-shiny/app')
mpgData <- readstata13::read.dta13("C:/Users/plutowl/Box/LAPOP Shared/2_Projects/2023 AB/Core_Regional/Data Processing/GM/Grand Merge 2004-2023 LAPOP AmericasBarometer (v1.0s).dta")
shiny::runApp('Documents/GitHub/lapop-shiny/app')
5+5
runApp('Documents/GitHub/lapop-shiny/app')
